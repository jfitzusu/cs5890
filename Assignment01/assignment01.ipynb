{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initializations"
      ],
      "metadata": {
        "id": "Sa88Qx07qu5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xs5ps7XY7i9K"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import neighbors\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "TRAIN_RATIO = 0.6\n",
        "VALIDATION_RATIO = 0.2\n",
        "TEST_RATIO = 0.2 \n",
        "QUALITY_THRESHOLD = 5\n",
        "\n",
        "DATA_PATH = 'data/winequality-white.csv'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1 \\\\\n",
        "Reads in data (expects the winequality-white.csv file in data subdirectory) "
      ],
      "metadata": {
        "id": "FZFiHmd7q8xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(DATA_PATH, header=0, delimiter=\";\")\n",
        "y = np.array([1 if quality > QUALITY_THRESHOLD else 0 for quality in X['quality'] ])\n",
        "X.drop('quality', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "fDnvJ74l_97A"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2: \\\\\n",
        "Calculates the ratio of ones and zeros"
      ],
      "metadata": {
        "id": "XpF6y6-NrPV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratioOnes = sum(y) / len(y)\n",
        "print(f\"The Dataset is {ratioOnes * 100: .2f}% oness and {(1 - ratioOnes) * 100: .2f}% Zeros\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As2W_iwCAhjY",
        "outputId": "7e80d899-90c3-439a-ea4b-5c9126d11f43"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dataset is  66.52% oness and  33.48% Zeros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3: \\\\\n",
        "Splits the data 60/20/20 for test/validate train, and reports the results \\\\\n",
        "Data is saved in the data as appropriatley named csv files"
      ],
      "metadata": {
        "id": "A2Uxa6wtrWJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, train_size=TRAIN_RATIO + VALIDATION_RATIO, stratify=y)\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_temp, y_temp, train_size=TRAIN_RATIO / (TRAIN_RATIO + VALIDATION_RATIO), stratify=y_temp)\n",
        "y_train, y_validate, y_test = pd.DataFrame(y_train), pd.DataFrame(y_validate), pd.DataFrame(y_test)\n",
        "print(f\"The size of the training set is {len(X_train)}\")\n",
        "print(f\"The size of the validation set is {len(X_validate)}\")\n",
        "print(f\"The size of the testing set is {len(X_test)}\")\n",
        "print(f\"The ratio is approximatley {len(X_train) / len(X) * 100:.0f}% Train, {len(X_validate) / len(X) * 100:.0f}% Validate, {len(X_test) / len(X)*100:.0f}% Test\")\n",
        "X_train.to_csv(\"data/trainX.csv\")\n",
        "X_validate.to_csv(\"data/validateX.csv\")\n",
        "X_test.to_csv(\"data/testX.csv\")\n",
        "y_train.to_csv(\"data/trainy.csv\")\n",
        "y_validate.to_csv(\"data/validatey.csv\")\n",
        "y_test.to_csv(\"data/testy.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfvSE8CmIv63",
        "outputId": "6f8a50b9-2d30-4d38-ed6b-71620f73a568"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the training set is 2938\n",
            "The size of the validation set is 980\n",
            "The size of the testing set is 980\n",
            "The ratio is approximatley 60% Train, 20% Validate, 20% Test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 4: \\\\\n",
        "Data is read from the data subdirectory, using naming conventions as seeen above \\\\\n",
        "Features are then standardized, and a single example is printed"
      ],
      "metadata": {
        "id": "Qtd6X8nvrieA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = pd.read_csv(\"data/trainX.csv\", index_col=0)\n",
        "X_validate = pd.read_csv(\"data/validateX.csv\", index_col=0)\n",
        "X_test = pd.read_csv(\"data/testX.csv\", index_col=0)\n",
        "y_train = pd.read_csv(\"data/trainy.csv\", index_col=0)['0'].values.tolist()\n",
        "y_validate = pd.read_csv(\"data/validatey.csv\", index_col=0)['0'].values.tolist()\n",
        "y_test = pd.read_csv(\"data/testy.csv\", index_col=0)['0'].values.tolist()\n",
        "scalar = StandardScaler().fit(X_train)\n",
        "standardized_X_train = scalar.transform(X_train) \n",
        "scalar = StandardScaler().fit(X_validate)\n",
        "standardized_X_validate = scalar.transform(X_validate) \n",
        "scalar = StandardScaler().fit(X_test)\n",
        "standardized_X_test = scalar.transform(X_test)\n"
      ],
      "metadata": {
        "id": "CN1MMYDLNPo5"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 5: \\\\\n",
        "A variaty of models are trained on the standardized data, and a report is generated for each based on validation data. \\\\"
      ],
      "metadata": {
        "id": "dxgY4hoYsCvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTemplate():\n",
        "    def __init__(self, baseName, generator, variants):\n",
        "        self.baseName = baseName\n",
        "        self.generator = generator\n",
        "        self.variants = variants\n",
        "\n",
        "def createLikeModels(modelData, reportData, savedModels):\n",
        "    for variant in modelData.variants:\n",
        "        model = modelData.generator(variant)\n",
        "        model.fit(standardized_X_train, y_train)\n",
        "        prediction = model.predict(standardized_X_validate)\n",
        "        trueP = 0\n",
        "        falseP = 0\n",
        "        trueN = 0\n",
        "        falseN = 0\n",
        "\n",
        "        for i in range(len(y_validate)):\n",
        "            if y_validate[i]:\n",
        "                if prediction[i]:\n",
        "                    trueP += 1\n",
        "                else:\n",
        "                    falseN += 1\n",
        "            else:\n",
        "                if prediction[i]:\n",
        "                    falseP += 1\n",
        "                else:\n",
        "                    trueN += 1\n",
        "\n",
        "        accuracy = (trueP + trueN) / len(prediction)\n",
        "        recall = trueP / (trueP + falseN)\n",
        "        precision = trueP / (trueP + falseP)\n",
        "        f1 = 2 * recall * precision / (recall + precision)\n",
        "\n",
        "        reportData[\"model\"].append(f\"{modelData.baseName}_{variant}\")\n",
        "        reportData[\"accuracy\"].append(accuracy)\n",
        "        reportData[\"precision\"].append(precision)\n",
        "        reportData[\"recall\"].append(recall)\n",
        "        reportData[\"f1\"].append(f1)\n",
        "\n",
        "        savedModels[f\"{modelData.baseName}_{variant}\"] = model\n",
        "    return\n",
        "\n",
        "data = {\n",
        "    \"model\": [],\n",
        "    \"accuracy\": [],    \n",
        "    \"precision\": [],\n",
        "    \"recall\": [],\n",
        "    \"f1\": []\n",
        "}\n",
        "\n",
        "trainedModels = {}\n",
        "\n",
        "modelTemplates = []\n",
        "modelTemplates.append(ModelTemplate(\"kNN\", lambda x: neighbors.KNeighborsClassifier(n_neighbors=x), [1,3,5]))\n",
        "modelTemplates.append(ModelTemplate(\"SVM\", lambda x: SVC(kernel=x), [\"rbf\", \"linear\", \"poly\"]))\n",
        "modelTemplates.append(ModelTemplate(\"TREE\", lambda x: DecisionTreeClassifier(criterion=x), [\"gini\", \"entropy\"]))\n",
        "modelTemplates.append(ModelTemplate(\"LOG_REG\", lambda x: LogisticRegression(penalty=x, solver=\"liblinear\"), [\"l1\", \"l2\"]))\n",
        "\n",
        "for template in modelTemplates:\n",
        "    createLikeModels(template, data, trainedModels)\n",
        "\n",
        "\n",
        "results = pd.DataFrame(data, columns=[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZahJ7Xlas4u",
        "outputId": "0cabab4c-e230-4c9b-fc9c-42dc03bd3abd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          model  accuracy  precision    recall        f1\n",
            "0         kNN_1  0.779592   0.831307  0.838957  0.835115\n",
            "1         kNN_3  0.756122   0.800582  0.843558  0.821509\n",
            "2         kNN_5  0.750000   0.791130  0.848160  0.818653\n",
            "3       SVM_rbf  0.771429   0.801408  0.872699  0.835536\n",
            "4    SVM_linear  0.755102   0.777628  0.884969  0.827834\n",
            "5      SVM_poly  0.732653   0.735507  0.934049  0.822973\n",
            "6     TREE_gini  0.713265   0.796800  0.763804  0.779953\n",
            "7  TREE_entropy  0.707143   0.778626  0.782209  0.780413\n",
            "8    LOG_REG_l1  0.753061   0.780822  0.874233  0.824891\n",
            "9    LOG_REG_l2  0.754082   0.781122  0.875767  0.825741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 6/7: \\\\\n",
        "The best model is selected using the highest f1 score, and a report is generated based on testing data. \\\\\n",
        "In this case, the best model ended up being SVM_rbf"
      ],
      "metadata": {
        "id": "yquhuLKusUDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reportTraining(model):\n",
        "    prediction = model.predict(standardized_X_test)\n",
        "    trueP = 0\n",
        "    falseP = 0\n",
        "    trueN = 0\n",
        "    falseN = 0\n",
        "\n",
        "    for i in range(len(y_test)):\n",
        "        if y_test[i]:\n",
        "            if prediction[i]:\n",
        "                trueP += 1\n",
        "            else:\n",
        "                falseN += 1\n",
        "        else:\n",
        "            if prediction[i]:\n",
        "                falseP += 1\n",
        "            else:\n",
        "                trueN += 1\n",
        "\n",
        "    accuracy = (trueP + trueN) / len(prediction)\n",
        "    recall = trueP / (trueP + falseN)\n",
        "    precision = trueP / (trueP + falseP)\n",
        "    f1 = 2 * recall * precision / (recall + precision)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(\"--------------------------------\")\n",
        "    print(f\"True Positives: {trueP}\", end='')\n",
        "    print(f\"    False Positives: {falseP}\")\n",
        "    print(f\"True Negatives: {trueN}\", end='')\n",
        "    print(f\"    False Negatives: {falseN}\")\n",
        "    print(\"--------------------------------\")\n",
        "    print()\n",
        "    print(\"Statistics:\")\n",
        "    print(\"--------------------------------\")\n",
        "    print(f\"Accuracy: {accuracy: .4f}\")\n",
        "    print(f\"Precision: {precision: .4f}\")\n",
        "    print(f\"Recall: {recall: .4f}\")\n",
        "    print(f\"F1: {f1: .4f}\")\n",
        "\n",
        "\n",
        "\n",
        "bestModel = results['model'].values[results['f1'].idxmax()]\n",
        "print(f\"The Best Model is {bestModel}\")\n",
        "print(\"------------------------------\")\n",
        "model = trainedModels[bestModel]\n",
        "reportTraining(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUPSHB8UceR4",
        "outputId": "3b75b013-4230-4dca-e019-c78f23b9bc2d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Best Model is SVM_rbf\n",
            "------------------------------\n",
            "Confusion Matrix:\n",
            "--------------------------------\n",
            "True Positives: 559    False Positives: 146\n",
            "True Negatives: 182    False Negatives: 93\n",
            "--------------------------------\n",
            "\n",
            "Statistics:\n",
            "--------------------------------\n",
            "Accuracy:  0.7561\n",
            "Precision:  0.7929\n",
            "Recall:  0.8574\n",
            "F1:  0.8239\n"
          ]
        }
      ]
    }
  ]
}